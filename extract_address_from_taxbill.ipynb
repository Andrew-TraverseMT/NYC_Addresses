{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrew-TraverseMT/NYC_Addresses/blob/main/extract_address_from_taxbill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook takes records from MapPluto and looks up parcel owner mailing addresses from property tax assessments using the BBL."
      ],
      "metadata": {
        "id": "xQ1Dw6pfZCJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "!pip install PyPDF2\n",
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xEXs752KQRs",
        "outputId": "dec1d50f-9f1b-41cb-b348-88770ad35ebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wWJ6U1OGKF_k"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pdfplumber\n",
        "import pymupdf\n",
        "import io\n",
        "import PyPDF2\n",
        "import re\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "import warnings\n",
        "import logging\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_text_from_url(url):\n",
        "    \"\"\"\n",
        "    Extracts all selectable text from each page of a PDF accessible via a URL, handling redirects.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL pointing to the PDF (or a redirect to the PDF).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of strings, where each string contains the text from one page.\n",
        "              If no text is found on a page, a message is included for that page.\n",
        "              If an error occurs, a list with an error message is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Download the PDF from the URL, following redirects\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}  # Add user-agent to avoid server blocks\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()  # Raise an error for bad status codes\n",
        "\n",
        "        # Check if the response content is a PDF\n",
        "        content_type = response.headers.get('Content-Type', '')\n",
        "        if 'application/pdf' not in content_type.lower():\n",
        "            return [\"Error: The URL does not point to a PDF file\"]\n",
        "\n",
        "        # Verify the content starts with %PDF to ensure it's a valid PDF\n",
        "        if not response.content.startswith(b'%PDF'):\n",
        "            return [\"Error: The response content is not a valid PDF\"]\n",
        "\n",
        "        # Try extracting text with pdfplumber\n",
        "        try:\n",
        "            with warnings.catch_warnings():  # Suppress CropBox warnings\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                with pdfplumber.open(io.BytesIO(response.content)) as pdf:\n",
        "                    all_text = []\n",
        "                    for page_number, page in enumerate(pdf.pages, start=1):\n",
        "                        text = page.extract_text()\n",
        "                        if text:\n",
        "                            # Clean the text by removing extra whitespace and empty lines\n",
        "                            cleaned_text = '\\n'.join(line.strip() for line in text.split('\\n') if line.strip())\n",
        "                            all_text.append(f\"Page {page_number}:\\n{cleaned_text}\")\n",
        "                        else:\n",
        "                            all_text.append(f\"Page {page_number}: No selectable text found\")\n",
        "                    return all_text\n",
        "        except Exception as e:\n",
        "            # Fallback to PyPDF2 if pdfplumber fails\n",
        "            try:\n",
        "                pdf_reader = PyPDF2.PdfReader(io.BytesIO(response.content))\n",
        "                all_text = []\n",
        "                for page_number, page in enumerate(pdf_reader.pages, start=1):\n",
        "                    text = page.extract_text()\n",
        "                    if text:\n",
        "                        cleaned_text = '\\n'.join(line.strip() for line in text.split('\\n') if line.strip())\n",
        "                        all_text.append(f\"Page {page_number}:\\n{cleaned_text}\")\n",
        "                    else:\n",
        "                        all_text.append(f\"Page {page_number}: No selectable text found\")\n",
        "                return all_text\n",
        "            except Exception as fallback_e:\n",
        "                return [f\"Error extracting text: pdfplumber failed with '{e}', PyPDF2 failed with '{fallback_e}'\"]\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return [f\"Error downloading PDF: {e}\"]\n",
        "    except Exception as e:\n",
        "        return [f\"Error processing PDF: {e}\"]\n",
        "\n",
        "# Example usage with your URL\n",
        "url = 'https://a836-edms.nyc.gov/dctm-rest/repositories/dofedmspts/StatementSearch?bbl=1000917502&stmtDate=20250215&stmtType=SOA'\n",
        "extracted_content = extract_all_text_from_url(url)\n",
        "\n",
        "# Print the extracted content for each page\n",
        "for page_content in extracted_content:\n",
        "    print(page_content)\n",
        "    print('-' * 50)  # Separator between pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMKEf45fCIQq",
        "outputId": "bf84f250-0a17-4541-f94f-574673ff5337"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1:\n",
            "80117992502150100140001 NYNP\n",
            "Property Tax Bill Quarterly  Statement\n",
            "Activity through February 15, 2025\n",
            "Owner name: 111 FULTON ST CONDO\n",
            "Property address: 111FULTON ST.\n",
            "Amount Due 04/01/25: $0.00\n",
            "#801179925021501#\n",
            "111 FULTON ST. CONDO\n",
            "ORSID REALTY CORP.\n",
            "156 W.56TH ST. FL. 6\n",
            "NEW YORK NY10019-39111400.01 -ZB -40 -4 -0 -2 -10736\n",
            "Borough: 1     Block: 00091     Lot:7502\n",
            "Write this in your check's memo line: BBL 1-00091-7502\n",
            "5536  10009175020  0000000000  250401  1  2025  1How much do I owe?\n",
            "Outstanding charges $0.00\n",
            "New charges $0.00\n",
            "Total amount due by April 1, 2025 * $0.00\n",
            "* To avoid interest, you must pay by April 15.\n",
            "Make checks payable & mail payment to:\n",
            "NYC Department of Finance\n",
            "PO Box 5536\n",
            "Binghamton NY  13902-5536Borough\n",
            "1Block\n",
            "00091Lot\n",
            "7502\n",
            "--------------------------------------------------\n",
            "Page 2:\n",
            "February 15, 2025\n",
            "111 Fulton st Condo\n",
            "111Fulton St.\n",
            "1-00091-7502\n",
            "Page2\n",
            "Billing Summary Amount\n",
            "Outstanding charges\n",
            "(Sum of unpaid balance and interest fees from billing periods)$0.00\n",
            "New charges\n",
            "(Sum of new property taxes and other charges-see below for details)$0.00\n",
            "AMOUNT DUE BY APRIL 1, 2025 $0.00\n",
            "Messages for You:\n",
            "Visitwww.nyc.gov/taxbill  toupdateyourmailingaddress,registertoreceivepropertytaxreceiptsbyemail,orlearnabout\n",
            "the interest rate charged on late payments.\n",
            "Homebankingpayment instructions: Logintoyourbankorbillpaywebsiteandadd\"NYCDepartment ofFinance\" as\n",
            "thepayee.YouraccountnumberisyourBBLnumber:1000917502.OuraddressisPOBox5536,Binghamton, NY\n",
            "13902-5536.\n",
            "Whenyouprovideacheckaspayment, youauthorize useithertouseinformation fromyourchecktomakeaone-time\n",
            "electronic fund transfer from your account or to process the payment as a check transaction.\n",
            "--------------------------------------------------\n",
            "Page 3:\n",
            "February 15, 2025\n",
            "111 Fulton st Condo\n",
            "111Fulton St.\n",
            "1-00091-7502\n",
            "Page3\n",
            "Additional Messages for You:\n",
            "Ifyouownincome-producing property, youmustfileaRealPropertyIncomeandExpense (RPIE)statement oraclaimof\n",
            "exclusion unlessyouareexemptbylaw.Youmustalsofileinformation aboutanygroundorsecondfloorstorefront units\n",
            "onthepremises, evenifyouareexemptfromfilinganRPIEstatement. RPIEfilerswhoseproperties haveanactual\n",
            "assessed valueof$750,000 orgreaterwillberequiredtofilerentrollinformation. ThedeadlinetofileisJune2,2025.\n",
            "Failuretofilewillresultinpenalties andinterest,whichwillbecomealienonyourpropertyiftheygounpaid.Visit\n",
            "www.nyc.gov/rpie  for more information.\n",
            "TheBIDassessment includesanadjustment duetoabillingcorrection fromaprioryear.Ifyouhaveanyquestions\n",
            "regarding BIDcharges, pleasecontacttheNYCDepartment ofSmallBusiness Services at(212)513-6300. Ifyouhave\n",
            "questions aboutanynon-BID-related charges, pleasecontacttheDepartment ofFinance bycalling311or(212)\n",
            "639-9675, or visit www.nyc.gov/contactdof.\n",
            "Compliance Notification\n",
            "Benchmarking EnergyandWaterUse: Thisproperty mayberequired tobenchmark itsenergyandwater\n",
            "consumption forcalendar year2024byMay1,2025,inaccordance withNYCBenchmarking Law84of2009as\n",
            "amended. For a detailed explanation of the requirements, please visit www.nyc.gov/LL84.\n",
            "Disclosure ofEnergyEfficiency ScoresandGrades: Ifyourproperty islistedontheCBLforbenchmarking\n",
            "compliance, itwillbeassigned anenergyefficiency gradebytheDepartment ofBuildings perLocalLaw33of2018\n",
            "as amended. For more information, visit www.nyc.gov/LL33.\n",
            "EnergyAuditsandRetro-Commissioning:  Thisproperty mayberequired tocomplete EnergyAuditsand\n",
            "Retro-Commissioning inaccordance withLocalLaw87of2009asamended. Formoreinformation, visit\n",
            "www.nyc.gov/LL87.\n",
            "Greenhouse GasEmission Reductions:  ThispropertymaybesubjecttoLocalLaw97of2019,asamended, which\n",
            "setscarbonemission limitsorprescriptive requirements forbuildings, withthefirstreportsduein2025.Allbuildings\n",
            "requiredtocomplywithLocalLaw97andLocalLaw88of2009,asamended, mustsubmittheirreportsbyMay1,\n",
            "2025,toavoidpenalties. Formoreinformation, visitwww.nyc.gov/LL97. Isyourbuildingprepared? ContactNYC\n",
            "Accelerator forcompliance support,financing options,andconnections tovettedserviceproviders. Formoredetails,\n",
            "visit www.accelerator.nyc/help or call (212) 656-9202.\n",
            "Reminder:  Thebuildingsustainability lawsnotedheretakeplaceatthelevelofanindividual building(asdesignated\n",
            "byabuildingidentification number, orBIN),eventhoughthecovered buildings areidentified bytaxlots(as\n",
            "designated byaborough-block-lot number, orBBL). Formore information, visit\n",
            "www.nyc.gov/site/buildings/codes/sustainability.page.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data into a DataFrame\n",
        "df = pd.read_csv(\"/content/subset_041125_update.csv\")\n",
        "\n",
        "# Display results\n",
        "print(df[['BoroCode', 'Block', 'Lot', 'BBL']])\n",
        "\n",
        "bbl_list = df['BBL'].to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwLPyNDQ7uUH",
        "outputId": "24b0666a-cfd6-4c7d-cc27-6ebd0485e371"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      BoroCode  Block  Lot         BBL\n",
            "0            2   2260    1  2022600001\n",
            "1            2   2260    4  2022600004\n",
            "2            2   2260   34  2022600034\n",
            "3            2   2261    3  2022610003\n",
            "4            2   2277    1  2022770001\n",
            "...        ...    ...  ...         ...\n",
            "2170         4  15008    8  4150080008\n",
            "2171         4  15008   33  4150080033\n",
            "2172         4  15009   25  4150090025\n",
            "2173         4  15009   51  4150090051\n",
            "2174         4  15012    6  4150120006\n",
            "\n",
            "[2175 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_text(url, max_retries=10, initial_delay=2):\n",
        "    \"\"\"\n",
        "    Download a PDF from a URL and extract text lines from the first page, with retries on connection errors.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the PDF to download.\n",
        "        max_retries (int): Maximum number of retry attempts (default: 10).\n",
        "        initial_delay (int): Initial delay in seconds before retrying (default: 2).\n",
        "\n",
        "    Returns:\n",
        "        list: Extracted text lines if successful, or an error message string if failed.\n",
        "    \"\"\"\n",
        "    delay = initial_delay\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Attempt to download the PDF\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()  # Raises an exception for HTTP errors (e.g., 404, 500)\n",
        "\n",
        "            # Verify the content is a PDF\n",
        "            content_type = response.headers.get('Content-Type', '')\n",
        "            if 'application/pdf' not in content_type.lower():\n",
        "                return f\"Error: URL does not point to a PDF file (Content-Type: {content_type})\"\n",
        "\n",
        "            # Verify content starts with %PDF\n",
        "            if not response.content.startswith(b'%PDF'):\n",
        "                return \"Error: Response content is not a valid PDF\"\n",
        "\n",
        "            # Try extracting text with pdfplumber first\n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress CropBox warnings\n",
        "                    pdf_file = io.BytesIO(response.content)\n",
        "                    with pdfplumber.open(pdf_file) as pdf:\n",
        "                        first_page = pdf.pages[0]\n",
        "                        text = first_page.extract_text()\n",
        "                        if not text:\n",
        "                            return \"Error: No text extracted from the PDF\"\n",
        "                        return text.split('\\n')\n",
        "            except Exception as e:\n",
        "                # Fallback to pymupdf if pdfplumber fails\n",
        "                try:\n",
        "                    pdf_file = io.BytesIO(response.content)\n",
        "                    with pymupdf.open(stream=pdf_file, filetype=\"pdf\") as doc:\n",
        "                        first_page = doc[0]\n",
        "                        text = first_page.get_text(\"text\")\n",
        "                        if not text:\n",
        "                            return \"Error: No text extracted from the PDF using pymupdf\"\n",
        "                        return text.split('\\n')\n",
        "                except Exception as fallback_e:\n",
        "                    return f\"Error extracting text: pdfplumber failed with '{e}', pymupdf failed with '{fallback_e}'\"\n",
        "\n",
        "        except requests.ConnectionError as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"Connection error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2  # Exponential backoff\n",
        "            else:\n",
        "                return f\"Error downloading PDF after {max_retries} attempts: {e}\"\n",
        "        except requests.HTTPError as e:\n",
        "            return f\"HTTP Error: {e}\"\n",
        "        except requests.RequestException as e:\n",
        "            return f\"Error downloading PDF: {e}\"\n",
        "\n",
        "def extract_address(lines):\n",
        "    \"\"\"Extract the mailing address starting after the line with two '#' symbols.\"\"\"\n",
        "    hash_line_index = -1\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.count('#') >= 2 and re.match(r'^#.*#$', line.strip()):\n",
        "            hash_line_index = i\n",
        "            break\n",
        "\n",
        "    if hash_line_index == -1 or hash_line_index + 1 >= len(lines):\n",
        "        return \"Address not found: No line with two '#' symbols or insufficient lines follow\"\n",
        "\n",
        "    address_lines = []\n",
        "    start_index = hash_line_index + 1\n",
        "\n",
        "    if start_index < len(lines):\n",
        "        line = lines[start_index].replace(\"Make checks payable & mail payment to:\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 1 < len(lines):\n",
        "        line = lines[start_index + 1].replace(\"NYC Department of Finance\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 2 < len(lines):\n",
        "        line = lines[start_index + 2].strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 4 < len(lines):\n",
        "        line = lines[start_index + 4].replace(\"Binghamton NY 13902-5536\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(address_lines)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Base URL template\n",
        "url_template = 'https://a836-edms.nyc.gov/dctm-rest/repositories/dofedmspts/StatementSearch?bbl={}&stmtDate=20250215&stmtType=SOA'"
      ],
      "metadata": {
        "id": "Pd4nOR92FTlo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress all pdfminer warnings by redirecting its logging\n",
        "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
        "\n",
        "# Set up logging for our application\n",
        "logging.basicConfig(\n",
        "    filename='bbl_processing.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def download_and_extract_text(url, max_retries=3, initial_delay=1):\n",
        "    \"\"\"\n",
        "    Download a PDF from a URL and extract text lines from the first page, with retries on connection errors.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the PDF to download.\n",
        "        max_retries (int): Maximum number of retry attempts (default: 3).\n",
        "        initial_delay (int): Initial delay in seconds before retrying (default: 1).\n",
        "\n",
        "    Returns:\n",
        "        list: Extracted text lines if successful, or an error message string if failed.\n",
        "    \"\"\"\n",
        "    delay = initial_delay\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Attempt to download the PDF\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Verify the content is a PDF\n",
        "            content_type = response.headers.get('Content-Type', '')\n",
        "            if 'application/pdf' not in content_type.lower():\n",
        "                return f\"Error: URL does not point to a PDF file (Content-Type: {content_type})\"\n",
        "\n",
        "            # Verify content starts with %PDF\n",
        "            if not response.content.startswith(b'%PDF'):\n",
        "                return \"Error: Response content is not a valid PDF\"\n",
        "\n",
        "            # Try extracting text with pdfplumber first\n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.simplefilter(\"ignore\")  # Additional safety\n",
        "                    pdf_file = io.BytesIO(response.content)\n",
        "                    with pdfplumber.open(pdf_file) as pdf:\n",
        "                        first_page = pdf.pages[0]\n",
        "                        text = first_page.extract_text()\n",
        "                        if not text:\n",
        "                            return \"Error: No text extracted from the PDF\"\n",
        "                        return text.split('\\n')\n",
        "            except Exception as e:\n",
        "                # Fallback to pymupdf\n",
        "                try:\n",
        "                    pdf_file = io.BytesIO(response.content)\n",
        "                    with pymupdf.open(stream=pdf_file, filetype=\"pdf\") as doc:\n",
        "                        first_page = doc[0]\n",
        "                        text = first_page.get_text(\"text\")\n",
        "                        if not text:\n",
        "                            return \"Error: No text extracted from the PDF using pymupdf\"\n",
        "                        return text.split('\\n')\n",
        "                except Exception as fallback_e:\n",
        "                    return f\"Error extracting text: pdfplumber failed with '{e}', pymupdf failed with '{fallback_e}'\"\n",
        "\n",
        "        except requests.ConnectionError as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                logging.warning(f\"Connection error for {url}: {e}. Retrying in {delay}s...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                return f\"Error downloading PDF after {max_retries} attempts: {e}\"\n",
        "        except requests.HTTPError as e:\n",
        "            return f\"HTTP Error: {e}\"\n",
        "        except requests.RequestException as e:\n",
        "            return f\"Error downloading PDF: {e}\"\n",
        "\n",
        "def extract_address(lines):\n",
        "    \"\"\"Extract the mailing address starting after the line with two '#' symbols.\"\"\"\n",
        "    hash_line_index = -1\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.count('#') >= 2 and re.match(r'^#.*#$', line.strip()):\n",
        "            hash_line_index = i\n",
        "            break\n",
        "\n",
        "    if hash_line_index == -1 or hash_line_index + 1 >= len(lines):\n",
        "        return \"Address not found: No line with two '#' symbols or insufficient lines follow\"\n",
        "\n",
        "    address_lines = []\n",
        "    start_index = hash_line_index + 1\n",
        "\n",
        "    if start_index < len(lines):\n",
        "        line = lines[start_index].replace(\"Make checks payable & mail payment to:\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 1 < len(lines):\n",
        "        line = lines[start_index + 1].replace(\"NYC Department of Finance\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 2 < len(lines):\n",
        "        line = lines[start_index + 2].strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    if start_index + 4 < len(lines):\n",
        "        line = lines[start_index + 4].replace(\"Binghamton NY 13902-5536\", \"\").strip()\n",
        "        address_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(address_lines)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Process each BBL with a clean progress bar\n",
        "for bbl in tqdm(bbl_list, desc=\"Processing BBLs\", file=sys.stdout):\n",
        "    try:\n",
        "        url = url_template.format(bbl)\n",
        "        logging.info(f\"Processing BBL {bbl}: {url}\")\n",
        "        text_lines = download_and_extract_text(url, max_retries=3, initial_delay=1)\n",
        "        if isinstance(text_lines, list):\n",
        "            address = extract_address(text_lines)\n",
        "            results[bbl] = address\n",
        "            logging.info(f\"Success for BBL {bbl}: {address}\")\n",
        "        else:\n",
        "            results[bbl] = text_lines\n",
        "            logging.warning(f\"Failed for BBL {bbl}: {text_lines}\")\n",
        "        time.sleep(0.5)  # Rate limiting\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Unexpected error for BBL {bbl}: {str(e)}\"\n",
        "        results[bbl] = error_msg\n",
        "        logging.error(error_msg)\n",
        "\n",
        "# Save results to a file\n",
        "with open('bbl_results.txt', 'w') as f:\n",
        "    for bbl, address in results.items():\n",
        "        f.write(f\"BBL: {bbl}\\nAddress:\\n{address}\\n{'-'*40}\\n\")\n",
        "\n",
        "# Print summary\n",
        "success_count = sum(1 for v in results.values() if not vstartswith(\"Error\"))\n",
        "print(f\"\\nProcessed {len(bbl_list)} BBLs: {success_count} successful, {len(bbl_list) - success_count} failed\")\n",
        "print(\"Detailed results saved to 'bbl_results.txt'\")"
      ],
      "metadata": {
        "id": "GC2Wp60f8Vqm",
        "outputId": "3be9173d-bd1c-452e-e78d-88a1a9d36743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BBLs:   4%|▍         | 97/2175 [01:06<25:11,  1.37it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join results with data and output a new csv\n",
        "\n",
        "results_df = pd.DataFrame(list(results.items()), columns=['BBL', 'Address'])\n",
        "\n",
        "df['BBL'] = df['BBL'].astype(str)\n",
        "results_df['BBL'] = results_df['BBL'].astype(str)\n",
        "\n",
        "merged_df = pd.merge(df, results_df, on='BBL', how='left')\n",
        "\n",
        "merged_df.to_csv(\"MapPluto_Subset_with_Mailing_Addr.csv\")"
      ],
      "metadata": {
        "id": "xrDKEn6rXSzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}